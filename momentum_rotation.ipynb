{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dominique-Thorendal-Research/momentum_rotation/blob/main/momentum_rotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd06e1d",
      "metadata": {
        "id": "7dd06e1d"
      },
      "source": [
        "\n",
        "# Momentum ETF Rotation â€” Learnâ€‘byâ€‘Doing Notebook\n",
        "\n",
        "This notebook teaches you how to build a **momentum ETF rotation** strategy using `yfinance` for data and `vectorbt` for backtesting.\n",
        "\n",
        "**Idea:** Every month, pick the **top N** ETFs by past **Xâ€‘day** return and hold them equally until next rebalance.\n",
        "\n",
        "You will learn:\n",
        "- Data download & cleaning\n",
        "- Feature engineering (rolling momentum)\n",
        "- Building target weights for rotation\n",
        "- Running a backtest with `vectorbt`\n",
        "- Interpreting stats\n",
        "- Doing a tiny parameter sweep\n",
        "- A quick train/test split for sanity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf97d67",
      "metadata": {
        "id": "1bf97d67"
      },
      "outputs": [],
      "source": [
        "# If you haven't installed these yet, run this cell once.\n",
        "# (In Anaconda/VSCode, using your working environment is fine.)\n",
        "# You can comment out lines that you already have installed.\n",
        "# Note: Restart kernel after install if imports fail.\n",
        "!pip install yfinance vectorbt backtesting bt matplotlib pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f862c490",
      "metadata": {
        "id": "f862c490"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import vectorbt as vbt\n",
        "\n",
        "pd.options.display.width = 120\n",
        "pd.options.display.max_columns = 20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5496c91c",
      "metadata": {
        "id": "5496c91c"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ef7e12",
      "metadata": {
        "id": "c6ef7e12"
      },
      "outputs": [],
      "source": [
        "# Universe: broad, diversified ETFs added later \"XLK\", \"XLF\", \"XLV\", \"LQD\", \"HYG\"]\n",
        "TICKERS = [\"SPY\", \"QQQ\", \"IWM\", \"EFA\", \"TLT\", \"GLD\", \"XLK\", \"XLV\"]\n",
        "START = \"2006-01-01\"         # multiple regimes\n",
        "INIT_CASH = 100_000\n",
        "FEES = 0.0025                 # 10 bps per trade before:0.001\n",
        "SLIPPAGE = 0.001            # 5 bps orig 0.0005\n",
        "\n",
        "# Base strategy params (we'll sweep them later)\n",
        "LOOKBACK_DAYS = 126           # ~3 months = 63\n",
        "TOP_N = 3                    # hold top 2\n",
        "REBAL_FREQ = \"M\"             # rebalance monthly\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59757021",
      "metadata": {
        "id": "59757021"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb091701",
      "metadata": {
        "id": "cb091701"
      },
      "source": [
        "## 1) Download & inspect prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "031bab2a",
      "metadata": {
        "id": "031bab2a"
      },
      "outputs": [],
      "source": [
        "px = yf.download(TICKERS, start=START)[\"Close\"].dropna(how=\"all\")\n",
        "px = px.loc[:, TICKERS].dropna()\n",
        "px.tail(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86283324",
      "metadata": {
        "id": "86283324"
      },
      "source": [
        "## 2) Choose rebalance dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8060e6f8",
      "metadata": {
        "id": "8060e6f8"
      },
      "outputs": [],
      "source": [
        "# Use last trading day of each month\n",
        "rebal_dates = px.resample(REBAL_FREQ).last().index\n",
        "rebal_dates[:5], rebal_dates[-5:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a54af1",
      "metadata": {
        "id": "99a54af1"
      },
      "source": [
        "## 3) Momentum feature (rolling total return)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b21f0a9",
      "metadata": {
        "id": "4b21f0a9"
      },
      "outputs": [],
      "source": [
        "# Rolling total return over LOOKBACK_DAYS\n",
        "momentum = px.pct_change(LOOKBACK_DAYS)\n",
        "\n",
        "# Align momentum to each rebal date (use last known value on that date)\n",
        "mom_on_rebal = momentum.reindex(rebal_dates, method=\"ffill\").dropna(how=\"all\")\n",
        "mom_on_rebal.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a5ced33",
      "metadata": {
        "id": "9a5ced33"
      },
      "outputs": [],
      "source": [
        "#momentum.tail()\n",
        "momentum.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942b4be7",
      "metadata": {
        "id": "942b4be7"
      },
      "source": [
        "## 4) Build target weights from ranks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strategy 1: Orig momentum"
      ],
      "metadata": {
        "id": "rmUETZzraYRO"
      },
      "id": "rmUETZzraYRO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8650ff6e",
      "metadata": {
        "id": "8650ff6e"
      },
      "outputs": [],
      "source": [
        "# Orig momentum strategy\n",
        "def build_rotation_weights(momentum_subset: pd.DataFrame, top_n: int) -> pd.DataFrame:\n",
        "    \"\"\"Equal-weight the top_n tickers by momentum at each rebalance date.\"\"\"\n",
        "    ranks = momentum_subset.rank(axis=1, ascending=False, method=\"first\")\n",
        "    select = (ranks <= top_n).astype(float)\n",
        "    w = select.div(select.sum(axis=1), axis=0).fillna(0.0)\n",
        "\n",
        "    return w\n",
        "\n",
        "w_rebal = build_rotation_weights(mom_on_rebal, TOP_N)\n",
        "w_rebal.tail()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Strategy 2: Risk Parity"
      ],
      "metadata": {
        "id": "728IxZ-hadTF"
      },
      "id": "728IxZ-hadTF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54e0513",
      "metadata": {
        "id": "a54e0513"
      },
      "outputs": [],
      "source": [
        "# Risk Parity\n",
        "def build_rp_weights(momentum_subset: pd.DataFrame, prices: pd.DataFrame, top_n: int, vol_window: int = 20) -> pd.DataFrame:\n",
        "    \"\"\"Risk-parity weighting within top_n winners.\"\"\"\n",
        "    ranks = momentum_subset.rank(axis=1, ascending=False, method=\"first\")\n",
        "    select = (ranks <= top_n).astype(float)\n",
        "\n",
        "    # Compute rolling vol (annualized optional)\n",
        "    vol = prices.pct_change().rolling(vol_window).std()\n",
        "    vol_r = vol.reindex(momentum_subset.index, method=\"ffill\")\n",
        "\n",
        "    # Inverse-vol weights among selected\n",
        "    inv_vol = 1 / vol_r\n",
        "    inv_vol = inv_vol * select  # zero out non-selected assets\n",
        "    w = inv_vol.div(inv_vol.sum(axis=1), axis=0).fillna(0.0)\n",
        "    return w\n",
        "\n",
        "w_rebal = build_rp_weights(mom_on_rebal, px, TOP_N)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Momentum > 0"
      ],
      "metadata": {
        "id": "KKMq1mRSb9ra"
      },
      "id": "KKMq1mRSb9ra"
    },
    {
      "cell_type": "code",
      "source": [
        "composite_mom = (mom_on_rebal * w_rebal).sum(axis=1)\n",
        "composite_mom.tail()\n",
        "risk_off = composite_mom < 0\n",
        "risk_off.tail()\n",
        "w_defensive = w_rebal.copy()\n",
        "\n",
        "for date in w_defensive.index:\n",
        "    if composite_mom.loc[date] < 0:\n",
        "        # Set all risky weights to 0, invest fully in TLT\n",
        "        w_defensive.loc[date] = 0\n",
        "        w_defensive.loc[date, \"TLT\"] = 1.0\n",
        "w_defensive\n"
      ],
      "metadata": {
        "id": "2cxdno0VcEPT"
      },
      "id": "2cxdno0VcEPT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b5d2d262",
      "metadata": {
        "id": "b5d2d262"
      },
      "source": [
        "## 5) Expand weights to all trading days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5519b7",
      "metadata": {
        "id": "1a5519b7"
      },
      "outputs": [],
      "source": [
        "# If using defensive (momentum <0 -> Treasury)\n",
        "#w_rebal = w_defensive.copy()\n",
        "\n",
        "# Forward-fill weights between rebalances\n",
        "w_all = w_rebal.reindex(px.index).fillna(method=\"ffill\").fillna(0.0)\n",
        "\n",
        "# Safety re-normalization in case of any row sum drift\n",
        "w_all = w_all.div(w_all.sum(axis=1).replace(0, np.nan), axis=0).fillna(0.0)\n",
        "w_all.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef8b1fd",
      "metadata": {
        "id": "8ef8b1fd"
      },
      "source": [
        "## 6) Backtest with `vectorbt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75bb8fe9",
      "metadata": {
        "id": "75bb8fe9"
      },
      "outputs": [],
      "source": [
        "import bt\n",
        "import ffn\n",
        "\n",
        "# --- helper: simple commission model (10 bps per notional trade) ---\n",
        "def bps_commissions(qty, price):\n",
        "    # qty is shares; notional = |qty| * price\n",
        "    # 10 bps = 0.001; change to FEES if you want to reuse your variable\n",
        "    return abs(qty) * price * FEES\n",
        "\n",
        "# Strategy: every month apply target weights from w_all and rebalance\n",
        "strat = bt.Strategy(\n",
        "    'MomentumRotation',\n",
        "    [\n",
        "        bt.algos.RunMonthly(),                 # act on monthly schedule\n",
        "        bt.algos.WeighTarget(w_all),           # use your target weight DF\n",
        "        bt.algos.Rebalance()                   # trade to targets\n",
        "    ]\n",
        ")\n",
        "\n",
        "bt_test = bt.Backtest(\n",
        "    strat,\n",
        "    px,                                       # price DataFrame\n",
        "    initial_capital=INIT_CASH,\n",
        "    commissions=bps_commissions,              # optional\n",
        "    progress_bar=False\n",
        ")\n",
        "\n",
        "res = bt.run(bt_test)\n",
        "res.plot()  # chart (optional)\n",
        "\n",
        "stats = res.stats\n",
        "stats.loc[['start', 'end', 'total_return', 'cagr', 'daily_sharpe', 'max_drawdown']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81e870b8",
      "metadata": {
        "id": "81e870b8"
      },
      "source": [
        "## 7) Parameter sweep (robustness check)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2dd730",
      "metadata": {
        "id": "cf2dd730"
      },
      "source": [
        "ðŸ§­ 7) Parameter Sweep â€“ Finding Robust Strategy Settings\n",
        "\n",
        "In this step, we test how sensitive our momentum rotation strategy is to different parameter choices:\n",
        "\n",
        "Lookback period (lookback_days) â†’ how far back we measure momentum (e.g., 2, 3, 4, 6 months).\n",
        "\n",
        "Top N (top_n) â†’ how many of the best-performing ETFs we hold each month.\n",
        "\n",
        "For each combination, the code:\n",
        "\n",
        "Builds momentum signals and target weights using make_rotation_weights().\n",
        "\n",
        "Runs a full backtest using bt (without commissions for speed and stability).\n",
        "\n",
        "Collects the daily Sharpe ratio as a performance score.\n",
        "\n",
        "Stores results in a table (grid_df) that ranks parameter sets from best to worst.\n",
        "\n",
        "This â€œparameter sweepâ€ helps you identify which lookback window and number of assets are most robust â€” instead of overfitting to one arbitrary choice.\n",
        "Youâ€™ll usually want to choose a region of stability (e.g., 63â€“84 days and Top 2 both work well), not just the single top Sharpe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939e4699",
      "metadata": {
        "id": "939e4699"
      },
      "outputs": [],
      "source": [
        "import bt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def make_rotation_weights(px_df: pd.DataFrame, lookback_days: int, top_n: int) -> pd.DataFrame:\n",
        "    momentum = px_df.pct_change(lookback_days)\n",
        "    rebal_dates = px_df.resample(\"M\").last().index\n",
        "    mom_r = momentum.reindex(rebal_dates, method=\"ffill\").dropna(how=\"all\")\n",
        "\n",
        "    ranks = mom_r.rank(axis=1, ascending=False, method=\"first\")\n",
        "    select = (ranks <= top_n).astype(float)\n",
        "    w_rebal = select.div(select.sum(axis=1), axis=0).fillna(0.0)\n",
        "\n",
        "    # Expand to daily and normalize\n",
        "    w_all = w_rebal.reindex(px_df.index).ffill().fillna(0.0)\n",
        "    w_all = w_all.div(w_all.sum(axis=1).replace(0, np.nan), axis=0).fillna(0.0)\n",
        "    return w_all\n",
        "\n",
        "def run_rotation_bt(px_df, lookback_days, top_n):\n",
        "    w = make_rotation_weights(px_df, lookback_days, top_n)\n",
        "    strat = bt.Strategy(\n",
        "        f\"Rot_{lookback_days}_{top_n}\",\n",
        "        [bt.algos.RunMonthly(), bt.algos.WeighTarget(w), bt.algos.Rebalance()]\n",
        "    )\n",
        "    # âš ï¸ commissions=None for stability/speed during sweep\n",
        "    bt_test = bt.Backtest(strat, px_df, initial_capital=INIT_CASH, progress_bar=False)\n",
        "    try:\n",
        "        res = bt.run(bt_test)\n",
        "        sharpe = float(res.stats.loc['daily_sharpe'])\n",
        "    except Exception as e:\n",
        "        # If anything blows up, return NaN so we can see it in the grid\n",
        "        print(f\"Param set failed (lb={lookback_days}, top_n={top_n}): {e}\")\n",
        "        sharpe = np.nan\n",
        "    return sharpe\n",
        "\n",
        "grid = []\n",
        "for lb in [42, 63, 84, 126]:   # ~2m, 3m, 4m, 6m\n",
        "    for tn in [1, 2, 3]:\n",
        "        grid.append({\"lookback\": lb, \"top_n\": tn, \"sharpe\": run_rotation_bt(px, lb, tn)})\n",
        "\n",
        "grid_df = pd.DataFrame(grid).sort_values(\"sharpe\", ascending=False)\n",
        "grid_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed8f902",
      "metadata": {
        "id": "2ed8f902"
      },
      "source": [
        "## 8) Train/Test split (out-of-sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b096eb5",
      "metadata": {
        "id": "6b096eb5"
      },
      "source": [
        "ðŸ” 8) Train/Test Split â€“ Out-of-Sample Validation\n",
        "\n",
        "Here, we check if the strategy generalizes by testing it on unseen data:\n",
        "\n",
        "The price data is split at December 2016 into a training period and a testing (out-of-sample) period.\n",
        "\n",
        "We build and backtest the same momentum strategy on each subset separately.\n",
        "\n",
        "Key performance metrics are compared â€” Total Return, CAGR, Sharpe Ratio, Max Drawdown â€” for both periods.\n",
        "\n",
        "If performance stays reasonably consistent between Train and Test, it suggests your strategy captures a real effect rather than noise or overfitting.\n",
        "\n",
        "(You can toggle commissions on/off with use_commissions=True for realism once the runs are stable.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407ade2e",
      "metadata": {
        "id": "407ade2e"
      },
      "outputs": [],
      "source": [
        "# Simple commission model (set to 0 for safety if needed)\n",
        "def bps_commissions(qty, price, bps=10):\n",
        "    return abs(qty) * price * (bps / 10_000)\n",
        "\n",
        "def backtest_with_weights(px_df, lookback_days, top_n, use_commissions=True):\n",
        "    w = make_rotation_weights(px_df, lookback_days, top_n)\n",
        "    strat = bt.Strategy(\n",
        "        \"MomentumRotation\",\n",
        "        [bt.algos.RunMonthly(), bt.algos.WeighTarget(w), bt.algos.Rebalance()]\n",
        "    )\n",
        "    commissions_fn = (lambda q, p: bps_commissions(q, p, bps=10)) if use_commissions else None\n",
        "    bt_test = bt.Backtest(\n",
        "        strat, px_df, initial_capital=INIT_CASH,\n",
        "        commissions=commissions_fn, progress_bar=False\n",
        "    )\n",
        "    res = bt.run(bt_test)\n",
        "    view = res.stats.loc[['total_return', 'cagr', 'daily_sharpe', 'max_drawdown']]\n",
        "    return res, view\n",
        "\n",
        "split_date = \"2016-12-31\"\n",
        "px_train = px.loc[:split_date]\n",
        "px_test  = px.loc[split_date:]\n",
        "\n",
        "# âœ”ï¸ Start with commissions off for stability; flip to True once it's working\n",
        "res_train, train_stats = backtest_with_weights(px_train, LOOKBACK_DAYS, TOP_N, use_commissions=False)\n",
        "res_test,  test_stats  = backtest_with_weights(px_test,  LOOKBACK_DAYS, TOP_N, use_commissions=False)\n",
        "\n",
        "print(\"=== TRAIN ===\")\n",
        "display(train_stats)\n",
        "print(\"=== TEST ===\")\n",
        "display(test_stats)\n",
        "\n",
        "# Optional: turn commissions on and re-run just once for your chosen params\n",
        "# res_train_c, train_stats_c = backtest_with_weights(px_train, LOOKBACK_DAYS, TOP_N, use_commissions=True)\n",
        "# res_test_c,  test_stats_c  = backtest_with_weights(px_test,  LOOKBACK_DAYS, TOP_N, use_commissions=True)\n",
        "# display(train_stats_c, test_stats_c)\n",
        "# res_train.plot(title=\"Train Equity Curve\")\n",
        "# res_test.plot(title=\"Test Equity Curve\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d36bd38",
      "metadata": {
        "id": "0d36bd38"
      },
      "outputs": [],
      "source": [
        "import bt\n",
        "\n",
        "# --- Optional: commissions toggle (set to None to keep it simple) ---\n",
        "def bps_commissions(qty, price, bps=10):\n",
        "    # One-time cost per trade; 10 bps = 0.001\n",
        "    return abs(qty) * price * (bps / 10_000)\n",
        "\n",
        "use_commissions = False\n",
        "commissions_fn = (lambda q, p: bps_commissions(q, p, bps=10)) if use_commissions else None\n",
        "\n",
        "# --- Helper to rebuild our rotation backtest with current params ---\n",
        "def build_rotation_backtest(px_df, lookback_days, top_n, name=\"MomentumRotation\", commissions_fn=None):\n",
        "    w = make_rotation_weights(px_df, lookback_days, top_n)\n",
        "    strat = bt.Strategy(\n",
        "        name,\n",
        "        [bt.algos.RunMonthly(), bt.algos.WeighTarget(w), bt.algos.Rebalance()]\n",
        "    )\n",
        "    return bt.Backtest(\n",
        "        strat, px_df, initial_capital=INIT_CASH,\n",
        "        commissions=commissions_fn, progress_bar=False\n",
        "    )\n",
        "\n",
        "# --- Buy & hold helpers ---\n",
        "def buy_and_hold_backtest(px_df, ticker, commissions_fn=None):\n",
        "    # Buy once at start, then sit tight\n",
        "    strat = bt.Strategy(\n",
        "        f\"BH_{ticker}\",\n",
        "        [bt.algos.RunOnce(),\n",
        "         bt.algos.SelectThese([ticker]),\n",
        "         bt.algos.WeighEqually(),\n",
        "         bt.algos.Rebalance()]\n",
        "    )\n",
        "    return bt.Backtest(\n",
        "        strat, px_df, initial_capital=INIT_CASH,\n",
        "        commissions=commissions_fn, progress_bar=False\n",
        "    )\n",
        "\n",
        "def buy_and_hold_equal_weight(px_df, commissions_fn=None):\n",
        "    strat = bt.Strategy(\n",
        "        \"BH_EQW\",\n",
        "        [bt.algos.RunOnce(),\n",
        "         bt.algos.SelectAll(),\n",
        "         bt.algos.WeighEqually(),\n",
        "         bt.algos.Rebalance()]\n",
        "    )\n",
        "    return bt.Backtest(\n",
        "        strat, px_df, initial_capital=INIT_CASH,\n",
        "        commissions=commissions_fn, progress_bar=False\n",
        "    )\n",
        "\n",
        "def sixty_forty_backtest(px_df, commissions_fn=None):\n",
        "    # Monthly rebalanced 60% SPY / 40% TLT\n",
        "    strat = bt.Strategy(\n",
        "        \"BH_60_40\",\n",
        "        [\n",
        "            bt.algos.RunMonthly(),               # rebalance monthly\n",
        "            bt.algos.SelectThese([\"SPY\", \"TLT\"]),\n",
        "            bt.algos.WeighSpecified(SPY=0.6, TLT=0.4),\n",
        "            bt.algos.Rebalance()\n",
        "        ]\n",
        "    )\n",
        "    return bt.Backtest(\n",
        "        strat, px_df, initial_capital=INIT_CASH,\n",
        "        commissions=commissions_fn, progress_bar=False\n",
        "    )\n",
        "\n",
        "# --- Build backtests ---\n",
        "bkt_rotation   = build_rotation_backtest(px, LOOKBACK_DAYS, TOP_N, commissions_fn=commissions_fn)\n",
        "bkt_bh_eqw     = buy_and_hold_equal_weight(px, commissions_fn=commissions_fn)\n",
        "bkt_benchmarks = [buy_and_hold_backtest(px, t, commissions_fn=commissions_fn) for t in TICKERS]\n",
        "bkt_60_40 = sixty_forty_backtest(px, commissions_fn=commissions_fn)\n",
        "\n",
        "# --- Run all together and plot ---\n",
        "res_cmp = bt.run(bkt_rotation, bkt_bh_eqw, bkt_60_40, *bkt_benchmarks)\n",
        "\n",
        "# Equity curves (normalized to initial capital). Interactive in VS Code/Jupyter.\n",
        "res_cmp.plot(title=\"Momentum Rotation vs Buy-and-Hold Benchmarks\")\n",
        "\n",
        "# Compact stats view for each strategy\n",
        "try:\n",
        "    # Some bt versions support .display(); if not, fall back to stats table\n",
        "    res_cmp.display()\n",
        "except Exception:\n",
        "    stats_tbl = res_cmp.stats  # one row per metric; columns per strategy\n",
        "    display(stats_tbl.loc[['total_return', 'cagr', 'daily_sharpe', 'max_drawdown']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d5ce469",
      "metadata": {
        "id": "5d5ce469"
      },
      "source": [
        "Sharpe Ratio = E(return)/Volatility\n",
        "SR = mu / sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e05a453b",
      "metadata": {
        "id": "e05a453b"
      },
      "source": [
        "\n",
        "## 9) Exercises (CFA L2 tieâ€‘ins)\n",
        "\n",
        "1. **Riskâ€‘parity within winners:** Compute 20â€‘day volatility per ETF and weight winners âˆ 1/vol instead of equal weight.  \n",
        "2. **Drawdown control:** If composite momentum (avg of winnersâ€™ momentum) < 0, rotate to `TLT` or cash.  \n",
        "3. **Cost sensitivity:** Re-run with `FEES = 0.0025`, `SLIPPAGE = 0.001` and compare Sharpe.  \n",
        "4. **Benchmark attribution:** Compare against a **60/40 (SPY/TLT)** benchmark: active return, active risk, information ratio.  \n",
        "5. **Universe variants:** Add sector ETFs (XLK, XLF, XLV) or credit (LQD, HYG) and reâ€‘test.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a95b2f5a",
      "metadata": {
        "id": "a95b2f5a"
      },
      "source": [
        "1. Org. top 3 3M lookback:\n",
        "    - sharpe:\n",
        "    - CAGR:\n",
        "\n",
        "2. Risk parity top 3 3M Lookback:\n",
        "3. Risk parity top 3 6M Lookback:\n",
        "      cagr\t0.119053\n",
        "      daily_sharpe\t0.900316\n",
        "      max_drawdown\t-0.262338\n",
        "4. Risk parity top 3 6M Lookback w/ defense:\n",
        "      total_return\t9.02364\n",
        "      cagr\t0.12315\n",
        "      daily_sharpe\t0.906965\n",
        "      max_drawdown\t-0.354734\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3 Cost Sensitivity\n",
        "*   4.\n",
        "total_return\t7.620296\n",
        "cagr\t0.114647\n",
        "daily_sharpe\t0.852019\n",
        "max_drawdown\t-0.361864\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0vpR9M3ffxXD"
      },
      "id": "0vpR9M3ffxXD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4 benchmark attribution\n",
        "total_return\t3.921744\n",
        "cagr\t0.083611\n",
        "daily_sharpe\t0.78803\n",
        "max_drawdown\t-0.311242"
      ],
      "metadata": {
        "id": "S8omhqP1h82B"
      },
      "id": "S8omhqP1h82B"
    },
    {
      "cell_type": "code",
      "source": [
        "prices = res_cmp.prices        # DataFrame: columns = strategy names\n",
        "rets = prices.pct_change().dropna()\n",
        "\n",
        "port_name  = \"MomentumRotation\"   # or whatever you called it\n",
        "bench_name = \"BH_60_40\"\n",
        "\n",
        "port_rets  = rets[port_name]\n",
        "bench_rets = rets[bench_name]\n",
        "active_rets = port_rets - bench_rets\n",
        "active_rets.tail(5)\n"
      ],
      "metadata": {
        "id": "LCsPcquIoYM-"
      },
      "id": "LCsPcquIoYM-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANN = 252  # trading days\n",
        "\n",
        "# Approximate annualized active return\n",
        "active_return_ann = active_rets.mean() * ANN\n",
        "\n",
        "# Annualized active risk (tracking error)\n",
        "active_risk_ann = active_rets.std() * (ANN ** 0.5)\n",
        "active_return_ann_exact = (1 + active_rets).prod() ** (ANN / len(active_rets)) - 1\n",
        "\n",
        "info_ratio = active_return_ann / active_risk_ann\n",
        "\n",
        "print(\"Active return (ann):\", active_return_ann)\n",
        "print(\"Active return exact (geometric) (ann):\", active_return_ann_exact)\n",
        "print(\"Active risk (ann):  \", active_risk_ann)\n",
        "print(\"Information ratio:  \", info_ratio)"
      ],
      "metadata": {
        "id": "PUxXhxRZohn_"
      },
      "id": "PUxXhxRZohn_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Active return: Return over the benchmark\n",
        "\n",
        "- What is active risk: standard deviation on active return\n",
        "\n",
        "- What is Information raio: =Active return/active risk\n",
        "- -> its like Sharpe ratio, but instead of comparing to rfr, you compare to benchmark"
      ],
      "metadata": {
        "id": "CpI94yYaop29"
      },
      "id": "CpI94yYaop29"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot asset selection\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- w_all is your daily weight DataFrame ---\n",
        "# (forward-filled version of w_rebal used for backtesting)\n",
        "\n",
        "# Make sure columns are in consistent order\n",
        "w_all = w_all[TICKERS]\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "w_all.plot.area(figsize=(14,6), linewidth=0, alpha=0.8)\n",
        "plt.title(\"Portfolio Asset Allocation Over Time\")\n",
        "plt.ylabel(\"Weight\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.legend(loc=\"upper left\", ncol=3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a_vYjQlIoZL7"
      },
      "id": "a_vYjQlIoZL7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- average weight per ETF across full backtest ---\n",
        "avg_alloc = w_all.mean() * 100  # in %\n",
        "\n",
        "# Option 1: Pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(avg_alloc, labels=avg_alloc.index, autopct=\"%1.1f%%\", startangle=90)\n",
        "plt.title(\"Average Portfolio Allocation Over Full Period\")\n",
        "plt.show()\n",
        "\n",
        "# Option 2: Bar chart (often clearer)\n",
        "plt.figure(figsize=(8,4))\n",
        "avg_alloc.sort_values().plot(kind=\"barh\", color=\"skyblue\")\n",
        "plt.title(\"Average Portfolio Allocation Over Full Period\")\n",
        "plt.xlabel(\"Average Weight (%)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "avg_alloc\n",
        "\n"
      ],
      "metadata": {
        "id": "LbhNdBFeadST"
      },
      "id": "LbhNdBFeadST",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Composite momentum per rebalance date ---\n",
        "# (average of the momenta of all assets or just winners, depending on your model)\n",
        "# If you already have mom_on_rebal and w_rebal:\n",
        "composite_mom = (mom_on_rebal * w_rebal).sum(axis=1)\n",
        "\n",
        "# Boolean: True when momentum < 0\n",
        "risk_off = composite_mom < 0\n",
        "\n",
        "# --- Summary statistics ---\n",
        "risk_off_ratio = risk_off.mean() * 100\n",
        "print(f\"Composite momentum < 0 in {risk_off_ratio:.1f}% of months \"\n",
        "      f\"({risk_off.sum()} out of {len(risk_off)} rebalancing periods).\")\n",
        "\n",
        "# --- Plot ---\n",
        "fig, ax = plt.subplots(figsize=(12,4))\n",
        "composite_mom.plot(ax=ax, color=\"steelblue\", lw=1.5)\n",
        "ax.axhline(0, color=\"black\", lw=1)\n",
        "ax.fill_between(\n",
        "    composite_mom.index,\n",
        "    0, composite_mom,\n",
        "    where=(composite_mom < 0),\n",
        "    color=\"salmon\", alpha=0.4, label=\"Momentum < 0\"\n",
        ")\n",
        "ax.set_title(\"Composite Momentum per Rebalance Date\")\n",
        "ax.set_ylabel(\"3-Month Average Momentum\")\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Aps5dAo9aqYR"
      },
      "id": "Aps5dAo9aqYR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}